<!-- 
[![PyPI](https://img.shields.io/pypi/v/llama-cpp-haystack)](https://pypi.org/project/llama-cpp-haystack/) 
![PyPI - Downloads](https://img.shields.io/pypi/dm/llama-cpp-haystack?color=blue&logo=pypi&logoColor=gold) 
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/llama-cpp-haystack?logo=python&logoColor=gold) 
-->
[![GitHub](https://img.shields.io/github/license/awinml/llama-cpp-haystack?color=green)](LICENSE) 
[![Actions status](https://github.com/awinml/llama-cpp-haystack/workflows/Test/badge.svg)](https://github.com/awinml/llama-cpp-haystack/actions)
[![Coverage Status](https://coveralls.io/repos/github/awinml/llama-cpp-haystack/badge.svg?branch=main)](https://coveralls.io/github/awinml/llama-cpp-haystack?branch=main)
[![Types - Mypy](https://img.shields.io/badge/types-Mypy-blue.svg)](https://github.com/python/mypy) 
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![Code Style - Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black) 



<h1 align="center"> <a href="https://github.com/awinml/llama-cpp-haystack"> Llama.cpp - Haystack </a> </h1>

Custom component for [Haystack](https://github.com/deepset-ai/haystack) (2.x) for running LLMs using the [Llama.cpp](https://github.com/ggerganov/llama.cpp) LLM framework. This implementation leverages the [Python Bindings for llama.cpp](https://github.com/abetlen/llama-cpp-python).

<!-- 
#### What's New

- **[v0.0.1 - 04/01/24]:** Added `LlamaCppGenerator` to run LLMs using llama.cpp.
-->

## Installation

```bash
pip install git+https://github.com/awinml/llama-cpp-haystack.git@main#egg=llama-cpp-haystack
```
<!-- 
## Usage


## Example


## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.
-->

## Author

[Ashwin Mathur](https://github.com/awinml)

## License

`llama-cpp-haystack` is distributed under the terms of the [Apache-2.0 license](https://github.com/awinml/llama-cpp-haystack/blob/main/LICENSE).
